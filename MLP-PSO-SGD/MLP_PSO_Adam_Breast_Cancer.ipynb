{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCsfTeVTzv6aAUZM3Ot89O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caua-sathler/NEURAL-NETWORKS/blob/main/MLP-PSO-SGD/MLP_PSO_Adam_Breast_Cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import copy\n",
        "import random\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 1) Carregar o dataset Breast Cancer\n",
        "data = load_breast_cancer()\n",
        "X = data.data           # shape (569, 30)\n",
        "y = data.target         # 0 ou 1\n",
        "\n",
        "# 2) Dividir em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# 3) Normalizar os dados\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 4) Converter para tensores PyTorch\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# 5) Definir a rede MLP\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 32)\n",
        "        self.fc2 = nn.Linear(32, 64)\n",
        "        self.fc3 = nn.Linear(64, 64)\n",
        "        self.fc4 = nn.Linear(64, 32)\n",
        "        self.fc5 = nn.Linear(32, 16)\n",
        "        self.fc6 = nn.Linear(16,8)\n",
        "        self.fc7 = nn.Linear(8, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = F.relu(self.fc5(x))\n",
        "        x = F.relu(self.fc6(x))\n",
        "        x = self.fc7(x)  # Saída final (logits)\n",
        "        return x\n",
        "\n",
        "# 6) Classe Partícula para PSO adaptado ao treinamento da rede neural\n",
        "class Particle:\n",
        "    def __init__(self, model, device):\n",
        "        self.model = copy.deepcopy(model).to(device)\n",
        "        self.best_model = copy.deepcopy(model).to(device)\n",
        "\n",
        "        # Limites do espaço de busca\n",
        "        low = -10.0\n",
        "        high = 10.0\n",
        "        velocity_scale = 0.1\n",
        "\n",
        "        # Inicializar posição e velocidade\n",
        "        self.position = {\n",
        "            name: torch.rand_like(param).to(device) * (high - low) + low\n",
        "            for name, param in model.named_parameters()\n",
        "        }\n",
        "        self.velocity = {\n",
        "            name: torch.randn_like(param).to(device) * velocity_scale\n",
        "            for name, param in model.named_parameters()\n",
        "        }\n",
        "\n",
        "        self.best_score = float('inf')\n",
        "        self.device = device\n",
        "\n",
        "        # Otimizador Adam para a partícula\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.0005, weight_decay=1e-5)\n",
        "\n",
        "    def pso_sgd(self, global_best_model, inertia, c1, c2, learning_rate, beta1, beta2, epsilon, m, v, t):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.grad is None:\n",
        "                continue\n",
        "\n",
        "            local_rand = random.random()\n",
        "            global_rand = random.random()\n",
        "\n",
        "            # Atualização da velocidade\n",
        "            self.velocity[name] = (\n",
        "                inertia * self.velocity[name]\n",
        "                + c1 * local_rand * (self.best_model.state_dict()[name].to(self.device) - param.data)\n",
        "                + c2 * global_rand * (global_best_model.state_dict()[name].to(self.device) - param.data)\n",
        "            )\n",
        "\n",
        "            # Atualizar posição\n",
        "            self.position[name] = param.data + self.velocity[name]\n",
        "            param.data = self.position[name]\n",
        "\n",
        "            # Atualização do Adam (simplificada)\n",
        "            m[name] = m[name].to(param.device)\n",
        "            v[name] = v[name].to(param.device)\n",
        "\n",
        "            m[name] = beta1 * m[name] + (1 - beta1) * param.grad\n",
        "            v[name] = beta2 * v[name] + (1 - beta2) * (param.grad ** 2)\n",
        "\n",
        "            m_hat = m[name] / (1 - beta1 ** t)\n",
        "            v_hat = v[name] / (1 - beta2 ** t)\n",
        "\n",
        "            # Aqui, substituído por um update \"simples\"\n",
        "            param.data = self.position[name] - learning_rate * param.grad\n",
        "\n",
        "    def evaluate_test(self, x_test, y_test, criterion):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(x_test)\n",
        "            loss = criterion(outputs, y_test)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            accuracy = (predicted == y_test).sum().item() / len(x_test)\n",
        "\n",
        "        avg_loss = loss.item()\n",
        "        return avg_loss, accuracy * 100\n",
        "\n",
        "    def evaluate_train(self, x_train, y_train, criterion):\n",
        "        self.model.train()\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        outputs = self.model(x_train)\n",
        "        loss = criterion(outputs, y_train)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        accuracy = (predicted == y_train).sum().item() / len(x_train)\n",
        "\n",
        "        avg_loss = loss.item()\n",
        "        return avg_loss, accuracy * 100\n",
        "\n",
        "# 7) Parâmetros do PSO\n",
        "pop_size = 10\n",
        "num_epochs = 150\n",
        "inertia = 0.9\n",
        "c1, c2 = 0.5, 0.9\n",
        "learning_rate = 0.0001\n",
        "beta1, beta2 = 0.5, 0.999\n",
        "epsilon = 1e-8\n",
        "\n",
        "# 8) Inicializar a rede para Breast Cancer\n",
        "# input_dim=30 (breast cancer) e output_dim=2 (classificação binária)\n",
        "model = MLP(input_dim=30, output_dim=2)\n",
        "particles = [Particle(model, device) for _ in range(pop_size)]\n",
        "\n",
        "global_best_model = copy.deepcopy(particles[0].model)\n",
        "global_best_score = float('inf')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Inicializar m e v para Adam\n",
        "m = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
        "v = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
        "\n",
        "# 9) Loop de treinamento do PSO\n",
        "for epoch in range(num_epochs):\n",
        "    # Atualizar inércia ao longo do tempo (opcional)\n",
        "    inertia = 0.9 - ((0.9 - 0.4) / num_epochs) * epoch\n",
        "\n",
        "    for particle in particles:\n",
        "        particle.model.train()\n",
        "        particle.optimizer.zero_grad()\n",
        "\n",
        "        # Atualizar posição (PSO + SGD)\n",
        "        particle.pso_sgd(global_best_model, inertia, c1, c2, learning_rate,\n",
        "                         beta1, beta2, epsilon, m, v, epoch + 1)\n",
        "\n",
        "        # Avaliar e atualizar o local best\n",
        "        val_loss, val_accuracy = particle.evaluate_train(X_train, y_train, criterion)\n",
        "        if val_loss < particle.best_score:\n",
        "            particle.best_score = val_loss\n",
        "            particle.best_model = copy.deepcopy(particle.model)\n",
        "\n",
        "    # Determinar e atualizar o g-best\n",
        "    best_particle = min(particles, key=lambda p: p.best_score)\n",
        "    if best_particle.best_score < global_best_score:\n",
        "        global_best_score = best_particle.best_score\n",
        "        global_best_model = copy.deepcopy(best_particle.best_model)\n",
        "\n",
        "    # Avaliar no conjunto de teste\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        val_loss, val_accuracy = best_particle.evaluate_test(X_test, y_test, criterion)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, '\n",
        "              f'Validation Loss: {val_loss:.2f}, '\n",
        "              f'Validation Accuracy: {val_accuracy:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtwaxUbpwCsE",
        "outputId": "fa6c17cd-973e-4782-f79b-a3b6f1b6ea11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/150, Validation Loss: 0.76, Validation Accuracy: 37.43\n",
            "Epoch 20/150, Validation Loss: 0.75, Validation Accuracy: 37.43\n",
            "Epoch 30/150, Validation Loss: 0.73, Validation Accuracy: 37.43\n",
            "Epoch 40/150, Validation Loss: 0.69, Validation Accuracy: 37.43\n",
            "Epoch 50/150, Validation Loss: 0.62, Validation Accuracy: 80.12\n",
            "Epoch 60/150, Validation Loss: 0.51, Validation Accuracy: 94.74\n",
            "Epoch 70/150, Validation Loss: 0.35, Validation Accuracy: 94.15\n",
            "Epoch 80/150, Validation Loss: 0.24, Validation Accuracy: 94.15\n",
            "Epoch 90/150, Validation Loss: 0.17, Validation Accuracy: 94.74\n",
            "Epoch 100/150, Validation Loss: 0.11, Validation Accuracy: 95.91\n",
            "Epoch 110/150, Validation Loss: 0.08, Validation Accuracy: 98.25\n",
            "Epoch 120/150, Validation Loss: 0.07, Validation Accuracy: 98.25\n",
            "Epoch 130/150, Validation Loss: 0.07, Validation Accuracy: 97.66\n",
            "Epoch 140/150, Validation Loss: 0.07, Validation Accuracy: 97.66\n",
            "Epoch 150/150, Validation Loss: 0.07, Validation Accuracy: 97.66\n"
          ]
        }
      ]
    }
  ]
}